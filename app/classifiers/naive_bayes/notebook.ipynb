{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# load data\n",
    "\n",
    "df = pd.read_csv(\"/Users/kakeng/Documents/education/MLLab/SpamClassifier/complete_spam_assassin.csv\")\n",
    "\n",
    "df = df[['Body', 'Label']]\n",
    "\n",
    "print(\"Shape: \" + str(df.shape) + \"\\n\")\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape: (6046, 2)\n",
      "\n",
      "                                                Body  Label\n",
      "0  \\nSave up to 70% on Life Insurance.\\nWhy Spend...      1\n",
      "1  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
      "2  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
      "3  ##############################################...      1\n",
      "4  I thought you might like these:\\n1) Slim Down ...      1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_classifier(vectorizer, X_train, y_train):\n",
    "\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train.values.astype(str))\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    classifier.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    return classifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# cross validation\n",
    "\n",
    "X = df[\"Body\"]\n",
    "y = df[\"Label\"]\n",
    "\n",
    "kfold = KFold(shuffle=True)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_indexes, test_indexes in kfold.split(X):\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    print(f\"Train ({train_indexes[0]} - {train_indexes[-1]}) & Test ({test_indexes[0]} - {test_indexes[-1]})\")\n",
    "    \n",
    "    classifier = get_classifier(vectorizer, X[train_indexes], y[train_indexes])\n",
    "    \n",
    "    X_test = vectorizer.transform(X[test_indexes].values.astype(str))\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    score = classifier.score(X_test, y_test)\n",
    "    \n",
    "    scores.append(score)\n",
    "    \n",
    "print()\n",
    "print(scores)\n",
    "print()\n",
    "print(\"Mean score: \", np.mean(scores))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train (0 - 6043) & Test (20 - 6045)\n",
      "Train (1 - 6045) & Test (0 - 6029)\n",
      "Train (0 - 6045) & Test (3 - 6040)\n",
      "Train (0 - 6045) & Test (9 - 6037)\n",
      "Train (0 - 6045) & Test (1 - 6043)\n",
      "\n",
      "[0.9619834710743802, 0.9495450785773366, 0.9611248966087675, 0.9545078577336642, 0.9454094292803971]\n",
      "\n",
      "Mean score:  0.954514146654909\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# train model\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_vectorized = vectorizer.fit_transform(X.values.astype(str))\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "classifier.fit(X_vectorized, y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# save model\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "with open('classifier.pkl', 'wb') as file:\n",
    "    pickle.dump(classifier, file)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit (conda)"
  },
  "interpreter": {
   "hash": "d2b78ae32893b8fcc4b49bde2c03793cfe7cc8e061d9421c443131a1e8a9ce51"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}